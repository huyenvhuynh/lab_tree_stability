{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: Trees and Model Stability\n",
    "\n",
    "Trees are notorious for being **unstable**: Small changes in the data can lead to noticeable or large changes in the tree. We're going to explore this phenomenon, and a common rebuttal.\n",
    "\n",
    "In the folder for this lab, there are three datasets that we used in class: Divorce, heart failure, and the AirBnB price dataset.\n",
    "\n",
    "1. Pick one of the datasets and appropriately clean it.\n",
    "2. Perform a train-test split for a specific seed (save the seed for reproducibility). Fit a classification/regression tree and a linear model on the training data and evaluate their performance on the test data. Set aside the predictions these models make.\n",
    "3. Repeat step 2 for three to five different seeds (save the seeds for reproducibility). How different are the trees that you get? Your linear model coefficients?. Set aside the predictions these models make.\n",
    "\n",
    "Typically, you would see the trees changing what appears to be a non-trivial amount, while the linear model coefficients don't vary nearly as much. Often, the changes appear substantial. \n",
    "\n",
    "But are they?\n",
    "\n",
    "4. Instead of focusing on the tree or model coefficients, do three things:\n",
    "    1. Make scatterplots of the predicted values on the test set from question 2 against the predicted values for the alternative models from part 3, separately for your trees and linear models. Do they appear reasonably similar?\n",
    "    2. Compute the correlation between your model in part 2 and your alternative models in part 3, separately for your trees and linear models. Are they highly correlated or not?\n",
    "    3. Run a simple linear regression of the predicted values on the test set from the alternative models on the predicted values from question 2, separately for your trees and linear models. Is the intercept close to zero? Is the slope close to 1? Is the $R^2$ close to 1?\n",
    "\n",
    "5. Do linear models appear to have similar coefficients and predictions across train/test splits? Do trees?\n",
    "6. True or false, and explain: \"Even if the models end up having a substantially different appearance, the predictions they generate are often very similar.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 2: MAIN SEED (0) RESULTS\n",
      "Tree RMSE: 14169.154\n",
      "Tree R^2: 0.060\n",
      "Linear RMSE: 9326.344\n",
      "Linear R^2: 0.381\n",
      "\n",
      "Question 3: OTHER SEED RESULTS\n",
      "\n",
      "Seed 7\n",
      "Tree RMSE: 36741.003, Tree R^2: -0.418\n",
      "Linear RMSE: 19463.556, Linear R^2: 0.249\n",
      "\n",
      "Seed 21\n",
      "Tree RMSE: 14987.259, Tree R^2: -0.177\n",
      "Linear RMSE: 7332.116, Linear R^2: 0.424\n",
      "\n",
      "Seed 42\n",
      "Tree RMSE: 18188.914, Tree R^2: -0.029\n",
      "Linear RMSE: 11918.809, Linear R^2: 0.325\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 1. Load and clean data\n",
    "\n",
    "df = pd.read_csv(\"./data/airbnb_hw.csv\") # Chose Airbnb dataset\n",
    "\n",
    "# Standardize column names\n",
    "df.columns = df.columns.str.strip().str.replace(\" \", \"_\")\n",
    "\n",
    "# Convert price column (string) into numeric\n",
    "df[\"Price_num\"] = (\n",
    "    df[\"Price\"]\n",
    "    .str.replace(\"$\", \"\", regex=False)\n",
    "    .str.replace(\",\", \"\", regex=False)\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "predictors = [\n",
    "    \"Neighbourhood\",\n",
    "    \"Property_Type\",\n",
    "    \"Room_Type\",\n",
    "    \"Review_Scores_Rating_(bin)\",\n",
    "    \"Zipcode\",\n",
    "    \"Beds\",\n",
    "    \"Number_of_Records\",\n",
    "    \"Number_Of_Reviews\",\n",
    "    \"Review_Scores_Rating\"\n",
    "]\n",
    "\n",
    "df_clean = df.dropna(subset=predictors + [\"Price_num\"]).copy()\n",
    "\n",
    "# One-hot encode categoricals\n",
    "X = pd.get_dummies(df_clean[predictors], drop_first=True)\n",
    "y = df_clean[\"Price_num\"]\n",
    "\n",
    "def fit_models(seed):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=seed\n",
    "    )\n",
    "\n",
    "    # Tree\n",
    "    tree = DecisionTreeRegressor(random_state=seed)\n",
    "    tree.fit(X_train, y_train)\n",
    "    tree_preds = tree.predict(X_test)\n",
    "\n",
    "    # Linear regression\n",
    "    lm = LinearRegression()\n",
    "    lm.fit(X_train, y_train)\n",
    "    lm_preds = lm.predict(X_test)\n",
    "\n",
    "    return {\n",
    "        \"seed\": seed,\n",
    "        \"tree\": tree,\n",
    "        \"lm\": lm,\n",
    "        \"tree_preds\": tree_preds,\n",
    "        \"lm_preds\": lm_preds,\n",
    "        \"X_test\": X_test,\n",
    "        \"y_test\": y_test,\n",
    "        \"tree_rmse\": mean_squared_error(y_test, tree_preds),\n",
    "        \"tree_r2\": r2_score(y_test, tree_preds),\n",
    "        \"lm_rmse\": mean_squared_error(y_test, lm_preds),\n",
    "        \"lm_r2\": r2_score(y_test, lm_preds),\n",
    "    }\n",
    "\n",
    "\n",
    "# 2\n",
    "\n",
    "main_seed = 0\n",
    "results_main = fit_models(main_seed)\n",
    "\n",
    "print(\"Question 2: MAIN SEED (0) RESULTS\")\n",
    "print(f\"Tree RMSE: {results_main['tree_rmse']:.3f}\")\n",
    "print(f\"Tree R^2: {results_main['tree_r2']:.3f}\")\n",
    "print(f\"Linear RMSE: {results_main['lm_rmse']:.3f}\")\n",
    "print(f\"Linear R^2: {results_main['lm_r2']:.3f}\")\n",
    "\n",
    "\n",
    "# 3\n",
    "other_seeds = [7, 21, 42]\n",
    "results_other = [fit_models(s) for s in other_seeds]\n",
    "\n",
    "print(\"\\nQuestion 3: OTHER SEED RESULTS\")\n",
    "for r in results_other:\n",
    "    print(f\"\\nSeed {r['seed']}\")\n",
    "    print(f\"Tree RMSE: {r['tree_rmse']:.3f}, Tree R^2: {r['tree_r2']:.3f}\")\n",
    "    print(f\"Linear RMSE: {r['lm_rmse']:.3f}, Linear R^2: {r['lm_r2']:.3f}\")\n",
    "\n",
    "# predictions on each seed's OWN test set\n",
    "tree_predictions = {r[\"seed\"]: r[\"tree_preds\"] for r in [results_main] + results_other}\n",
    "lm_predictions   = {r[\"seed\"]: r[\"lm_preds\"]   for r in [results_main] + results_other}\n",
    "\n",
    "X_test_main = results_main[\"X_test\"]\n",
    "y_test_main = results_main[\"y_test\"]\n",
    "\n",
    "tree_preds_common = {}\n",
    "lm_preds_common = {}\n",
    "\n",
    "for r in [results_main] + results_other:\n",
    "    seed = r[\"seed\"]\n",
    "    tree_preds_common[seed] = r[\"tree\"].predict(X_test_main)\n",
    "    lm_preds_common[seed]   = r[\"lm\"].predict(X_test_main)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We chose the airbnb_hw.csv dataset. To clean this dataset, we standardized the column names, replacing spaces with underscores. We also converted the Price column to a numeric variable Price_num by removing any $ or , characters and casting to float, dropping the null values and encoding the categorical columns.\n",
    "\n",
    "2. Code above. For the seed 0, the Tree RMSE and R^2 was 14169.154 and 0.060 respectively, while the Linear RMSE and Linear R^2 was 9326.344 and 0.381.\n",
    "\n",
    "3. Across the different seeds, the decision trees changed a lot. Their test RMSE values jumped from about 14K (seed 0) to 36K (seed 7), and the R² values even became negative for every alternative seed. This shows that the tree structure and its predictive behavior are highly unstable: small changes in the data lead to very different splits and very different performance. The linear models were noticeably more stable. Their RMSE values moved, but not nearly as dramatically, and the R² values stayed within a narrower range (about 0.25–0.42). Even when performance changed, the linear model’s coefficients remained much more consistent across seeds. Overall, the trees varied substantially, while the linear models changed only moderately."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
